{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example of [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n",
    "1. Example of corpus\n",
    "2. Preprocessing and Tokenizing\n",
    "3. Calculating bag of words\n",
    "4. TF\n",
    "5. IDF\n",
    "6. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "corpus = \"\"\"\n",
    "Armstrong Calculus\n",
    "Arts Integration in Elementary Curriculum: 2nd Edition\n",
    "Becoming America: An Exploration of American Literature from Precolonial to Post-Revolution\n",
    "\"\"\".split(\"\\n\")[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['armstrong', 'calculus']\n",
      "['arts', 'integration', 'in', 'elementary', 'curriculum:', '2nd', 'edition']\n",
      "['becoming', 'america:', 'an', 'exploration', 'of', 'american', 'literature', 'from', 'precolonial', 'to', 'post-revolution']\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "l_A = corpus[0].lower().split()\n",
    "l_B = corpus[1].lower().split()\n",
    "l_C = corpus[2].lower().split()\n",
    "\n",
    "print(l_A)\n",
    "print(l_B)\n",
    "print(l_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to', 'in', 'literature', 'precolonial', 'arts', 'elementary', 'calculus', 'integration', 'becoming', 'curriculum:', 'edition', 'from', 'exploration', 'american', 'america:', 'post-revolution', 'armstrong', 'an', 'of', '2nd'}\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "word_set = set(l_A).union(set(l_B)).union(set(l_C))\n",
    "print(word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>to</th>\n",
       "      <th>in</th>\n",
       "      <th>literature</th>\n",
       "      <th>precolonial</th>\n",
       "      <th>arts</th>\n",
       "      <th>elementary</th>\n",
       "      <th>calculus</th>\n",
       "      <th>integration</th>\n",
       "      <th>becoming</th>\n",
       "      <th>curriculum:</th>\n",
       "      <th>edition</th>\n",
       "      <th>from</th>\n",
       "      <th>exploration</th>\n",
       "      <th>american</th>\n",
       "      <th>america:</th>\n",
       "      <th>post-revolution</th>\n",
       "      <th>armstrong</th>\n",
       "      <th>an</th>\n",
       "      <th>of</th>\n",
       "      <th>2nd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   to  in  literature  precolonial  arts  elementary  calculus  integration  \\\n",
       "0   0   0           0            0     0           0         1            0   \n",
       "1   0   1           0            0     1           1         0            1   \n",
       "2   1   0           1            1     0           0         0            0   \n",
       "\n",
       "   becoming  curriculum:  edition  from  exploration  american  america:  \\\n",
       "0         0            0        0     0            0         0         0   \n",
       "1         0            1        1     0            0         0         0   \n",
       "2         1            0        0     1            1         1         1   \n",
       "\n",
       "   post-revolution  armstrong  an  of  2nd  \n",
       "0                0          1   0   0    0  \n",
       "1                0          0   0   0    1  \n",
       "2                1          0   1   1    0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict_A = dict.fromkeys(word_set, 0)\n",
    "word_dict_B = dict.fromkeys(word_set, 0)\n",
    "word_dict_C = dict.fromkeys(word_set, 0)\n",
    "\n",
    "for word in l_A:\n",
    "    word_dict_A[word] += 1\n",
    "\n",
    "for word in l_B:\n",
    "    word_dict_B[word] += 1\n",
    "\n",
    "for word in l_C:\n",
    "    word_dict_C[word] += 1\n",
    "\n",
    "pd.DataFrame([word_dict_A, word_dict_B, word_dict_C])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#4 tf - term frequency\n",
    "In the case of the term frequency $tf(t,d)$, the simplest choice is to use the raw count of a term in a string. \n",
    "$${\\displaystyle \\mathrm {tf} (t,d)={\\frac {n_{t}}{\\sum _{k}n_{k}}}} $$\n",
    "where $n_t$ is the number of occurrences of the word $t$ in the string, and in the denominator - the total number of words in this string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(word_dict, l):\n",
    "    tf = {}\n",
    "    sum_nk = len(l)\n",
    "    for word, count in word_dict.items():\n",
    "        tf[word] = count/sum_nk\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frecuencia de termino (tf)\n",
    "tf_A = compute_tf(word_dict_A, l_A)\n",
    "tf_B = compute_tf(word_dict_B, l_B)\n",
    "tf_C = compute_tf(word_dict_C, l_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\#5 idf - inverse document frequency\n",
    "idf is a measure of how much information the word provides\n",
    "$$ \\mathrm{idf}(t, D) =  \\log \\frac{N}{|\\{d \\in D: t \\in d\\}|} $$\n",
    "- $N$: total number of strings in the corpus ${\\displaystyle N={|D|}}$\n",
    "- ${\\displaystyle |\\{d\\in D:t\\in d\\}|}$  : number of strings where the term ${\\displaystyle t}$ appears (i.e., ${\\displaystyle \\mathrm {tf} (t,d)\\neq 0})$. If the term is not in the corpus, this will lead to a division-by-zero. It is therefore common to adjust the denominator to ${\\displaystyle 1+|\\{d\\in D:t\\in d\\}|}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(strings_list):\n",
    "    n = len(strings_list)\n",
    "    idf = dict.fromkeys(strings_list[0].keys(), 0)\n",
    "    for l in strings_list:\n",
    "        for word, count in l.items():\n",
    "            if count > 0:\n",
    "                idf[word] += 1\n",
    "    \n",
    "    for word, v in idf.items():\n",
    "        idf[word] = log(n / float(v))\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frecuencia de documento Inversa\n",
    "idf = compute_idf([word_dict_A, word_dict_B, word_dict_C])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\# 6 tf-idf\n",
    "Then tfâ€“idf is calculated as\n",
    "$$ {\\displaystyle \\mathrm {tfidf} (t,d,D)=\\mathrm {tf} (t,d)\\cdot \\mathrm {idf} (t,D)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf_idf(tf, idf):\n",
    "    tf_idf = dict.fromkeys(tf.keys(), 0)\n",
    "    for word, v in tf.items():\n",
    "        tf_idf[word] = v * idf[word]\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_A = compute_tf_idf(tf_A, idf)\n",
    "tf_idf_B = compute_tf_idf(tf_B, idf)\n",
    "tf_idf_C = compute_tf_idf(tf_C, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>to</th>\n",
       "      <th>in</th>\n",
       "      <th>literature</th>\n",
       "      <th>precolonial</th>\n",
       "      <th>arts</th>\n",
       "      <th>elementary</th>\n",
       "      <th>calculus</th>\n",
       "      <th>integration</th>\n",
       "      <th>becoming</th>\n",
       "      <th>curriculum:</th>\n",
       "      <th>edition</th>\n",
       "      <th>from</th>\n",
       "      <th>exploration</th>\n",
       "      <th>american</th>\n",
       "      <th>america:</th>\n",
       "      <th>post-revolution</th>\n",
       "      <th>armstrong</th>\n",
       "      <th>an</th>\n",
       "      <th>of</th>\n",
       "      <th>2nd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.549306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.549306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>0.156945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         to        in  literature  precolonial      arts  elementary  \\\n",
       "0  0.000000  0.000000    0.000000     0.000000  0.000000    0.000000   \n",
       "1  0.000000  0.156945    0.000000     0.000000  0.156945    0.156945   \n",
       "2  0.099874  0.000000    0.099874     0.099874  0.000000    0.000000   \n",
       "\n",
       "   calculus  integration  becoming  curriculum:   edition      from  \\\n",
       "0  0.549306     0.000000  0.000000     0.000000  0.000000  0.000000   \n",
       "1  0.000000     0.156945  0.000000     0.156945  0.156945  0.000000   \n",
       "2  0.000000     0.000000  0.099874     0.000000  0.000000  0.099874   \n",
       "\n",
       "   exploration  american  america:  post-revolution  armstrong        an  \\\n",
       "0     0.000000  0.000000  0.000000         0.000000   0.549306  0.000000   \n",
       "1     0.000000  0.000000  0.000000         0.000000   0.000000  0.000000   \n",
       "2     0.099874  0.099874  0.099874         0.099874   0.000000  0.099874   \n",
       "\n",
       "         of       2nd  \n",
       "0  0.000000  0.000000  \n",
       "1  0.000000  0.156945  \n",
       "2  0.099874  0.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTf_Idf = pd.DataFrame([tf_idf_A, tf_idf_B, tf_idf_C])\n",
    "dataTf_Idf\n",
    "#dataTf_Idf.dtypes\n",
    "#to print heads\n",
    "#dataTf_Idf.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For clustering we must use tf-idf weights\n",
    "the example above is just an example, in practice it is better to apply [TfidfVectorizer from sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.54930614 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.54930614 0.\n",
      "  0.         0.        ]\n",
      " [0.04993692 0.07847231 0.04993692 0.04993692 0.07847231 0.07847231\n",
      "  0.         0.07847231 0.04993692 0.07847231 0.07847231 0.04993692\n",
      "  0.04993692 0.04993692 0.04993692 0.04993692 0.         0.04993692\n",
      "  0.04993692 0.07847231]]\n"
     ]
    }
   ],
   "source": [
    "myKmeans = KMeans(n_clusters=2).fit(dataTf_Idf)\n",
    "centroids = myKmeans.cluster_centers_\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cheese'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Projects/Python/TriplesIntegration/venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cheese'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-68c29c93114e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataTf_Idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cheese'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataTf_Idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'with'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataTf_Idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'simple'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataTf_Idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cats'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataTf_Idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'another'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmyKmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Python/TriplesIntegration/venv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Python/TriplesIntegration/venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cheese'"
     ]
    }
   ],
   "source": [
    "plt.scatter(dataTf_Idf['cheese'],dataTf_Idf['with'],dataTf_Idf['simple'],dataTf_Idf['cats'],dataTf_Idf['another'], c= myKmeans.labels_.astype(float), s=50, alpha=0.5)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full text for clusterring\n",
    "\n",
    "This corpus contain some strings about Google and some strings about TF-IDF from Wikipedia. Just for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = \"\"\"\n",
    "Google and Facebook are strangling the free press to death. Democracy is the loser\n",
    "Your 60-second guide to security stuff Google touted today at Next '18\n",
    "A Guide to Using Android Without Selling Your Soul to Google\n",
    "Review: Lenovoâ€™s Google Smart Display is pretty and intelligent\n",
    "Google Maps user spots mysterious object submerged off the coast of Greece - and no-one knows what it is\n",
    "Android is better than IOS\n",
    "In information retrieval, tfâ€“idf or TFIDF, short for term frequencyâ€“inverse document frequency\n",
    "is a numerical statistic that is intended to reflect\n",
    "how important a word is to a document in a collection or corpus.\n",
    "It is often used as a weighting factor in searches of information retrieval\n",
    "text mining, and user modeling. The tf-idf value increases proportionally\n",
    "to the number of times a word appears in the document\n",
    "and is offset by the frequency of the word in the corpus\n",
    "\"\"\".split(\"\\n\")[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and tokenizing\n",
    "Firstly, we must bring every chars to lowercase and remove all punctuation, because it's not important for our task, but is very harmful for clustering algorithm. \n",
    "After that, we'll split strings to array of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate tf-idf for this corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocessing)\n",
    "tfidf = tfidf_vectorizer.fit_transform(all_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train simple kmeans model with k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2).fit(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_for_predicting = [\"tf and idf is awesome!\", \"some androids is there\"]\n",
    "kmeans.predict(tfidf_vectorizer.transform(lines_for_predicting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TriplesIntegration",
   "language": "python",
   "name": "triplesintegration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
